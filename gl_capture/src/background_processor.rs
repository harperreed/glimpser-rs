//! ABOUTME: Background FFmpeg processor for handling snapshot generation without blocking
//! ABOUTME: Provides job queue and status tracking for long-running FFmpeg operations

use crate::{
    generate_snapshot_with_ffmpeg,
    snapshot_limiter::{SnapshotLimiterConfig, SnapshotResourceLimiter},
    SnapshotConfig,
};
use bytes::Bytes;
use gl_core::{time::now_iso8601, Error, Id, Result};
use serde::{Deserialize, Serialize};
use std::{
    collections::HashMap,
    path::PathBuf,
    sync::{Arc, RwLock},
    time::Duration,
};
use tokio::{
    sync::{mpsc, oneshot},
    task::JoinHandle,
    time::timeout,
};
use tracing::{debug, error, info, instrument, warn};

/// Status of a background snapshot job
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum JobStatus {
    /// Job is queued and waiting to be processed
    Pending,
    /// Job is currently being processed
    Processing,
    /// Job completed successfully
    Completed,
    /// Job failed with an error
    Failed,
    /// Job was cancelled
    Cancelled,
}

/// A background snapshot generation job
#[derive(Debug, Clone)]
pub struct SnapshotJob {
    pub id: String,
    pub input_path: PathBuf,
    pub config: SnapshotConfig,
    pub created_at: String,
    pub updated_at: String,
    pub status: JobStatus,
    pub error_message: Option<String>,
    pub result: Option<Bytes>,
}

impl SnapshotJob {
    pub fn new(input_path: PathBuf, config: SnapshotConfig) -> Self {
        let now = now_iso8601();
        Self {
            id: Id::new().to_string(),
            input_path,
            config,
            created_at: now.clone(),
            updated_at: now,
            status: JobStatus::Pending,
            error_message: None,
            result: None,
        }
    }
}

/// Request to process a snapshot in the background
#[derive(Debug)]
struct ProcessRequest {
    job: SnapshotJob,
    result_sender: oneshot::Sender<Result<Bytes>>,
}

/// Background snapshot processor that handles FFmpeg operations in a separate thread pool
#[derive(Debug)]
pub struct BackgroundSnapshotProcessor {
    /// Job storage for status tracking
    jobs: Arc<RwLock<HashMap<String, SnapshotJob>>>,
    /// Channel for sending processing requests
    request_sender: mpsc::UnboundedSender<ProcessRequest>,
    /// Handle to the background processing task
    _processor_handle: JoinHandle<()>,
    /// Resource limiter to prevent thread pool exhaustion
    limiter: SnapshotResourceLimiter,
}

impl BackgroundSnapshotProcessor {
    /// Create a new background snapshot processor
    pub fn new() -> Self {
        Self::with_config(SnapshotLimiterConfig::default())
    }

    /// Create a new background snapshot processor with custom limiter configuration
    pub fn with_config(limiter_config: SnapshotLimiterConfig) -> Self {
        let jobs = Arc::new(RwLock::new(HashMap::new()));
        let (request_sender, request_receiver) = mpsc::unbounded_channel();
        let limiter = SnapshotResourceLimiter::new(limiter_config);

        let jobs_clone = jobs.clone();
        let limiter_clone = limiter.clone();
        let processor_handle = tokio::spawn(async move {
            Self::process_requests(jobs_clone, request_receiver, limiter_clone).await;
        });

        Self {
            jobs,
            request_sender,
            _processor_handle: processor_handle,
            limiter,
        }
    }

    /// Submit a snapshot job for background processing
    /// Returns immediately with a job ID for status checking
    #[instrument(skip(self, input_path, config))]
    pub async fn submit_job(&self, input_path: PathBuf, config: SnapshotConfig) -> Result<String> {
        let job = SnapshotJob::new(input_path, config);
        let job_id = job.id.clone();

        debug!(job_id = %job_id, path = %job.input_path.display(), "Submitting background snapshot job");

        // Store the job
        {
            let mut jobs = self.jobs.write().unwrap();
            jobs.insert(job_id.clone(), job.clone());
        }

        // Create a oneshot channel for the result (we won't wait for it here)
        let (result_sender, _result_receiver) = oneshot::channel();

        let request = ProcessRequest { job, result_sender };

        // Send the request to the background processor
        self.request_sender
            .send(request)
            .map_err(|_| Error::Config("Background processor is not available".to_string()))?;

        info!(job_id = %job_id, "Background snapshot job submitted successfully");
        Ok(job_id)
    }

    /// Submit a background snapshot job with a specific job ID
    /// This is useful when the job ID is generated by an external system (like database)
    pub async fn submit_job_with_id(
        &self,
        job_id: String,
        input_path: PathBuf,
        config: SnapshotConfig,
    ) -> Result<()> {
        debug!(job_id = %job_id, path = %input_path.display(), "Submitting background snapshot job with specific ID");

        let mut job = SnapshotJob::new(input_path, config);
        job.id = job_id.clone(); // Override the generated ID with the provided one

        // Store the job
        {
            let mut jobs = self.jobs.write().unwrap();
            jobs.insert(job_id.clone(), job.clone());
        }

        // Create a oneshot channel for the result (we won't wait for it here)
        let (result_sender, _result_receiver) = oneshot::channel();

        let request = ProcessRequest { job, result_sender };

        // Send the request to the background processor
        self.request_sender
            .send(request)
            .map_err(|_| Error::Config("Background processor is not available".to_string()))?;

        info!(job_id = %job_id, "Background snapshot job with specific ID submitted successfully");
        Ok(())
    }

    /// Process a snapshot job synchronously and return the result
    /// This method still uses background processing but waits for completion
    #[instrument(skip(self, input_path, config))]
    pub async fn process_job_sync(
        &self,
        input_path: PathBuf,
        config: SnapshotConfig,
    ) -> Result<Bytes> {
        let job = SnapshotJob::new(input_path, config);
        let job_id = job.id.clone();

        debug!(job_id = %job_id, path = %job.input_path.display(), "Processing snapshot job synchronously");

        // Store the job
        {
            let mut jobs = self.jobs.write().unwrap();
            jobs.insert(job_id.clone(), job.clone());
        }

        // Create a oneshot channel to wait for the result
        let (result_sender, result_receiver) = oneshot::channel();

        let request = ProcessRequest { job, result_sender };

        // Send the request to the background processor
        self.request_sender
            .send(request)
            .map_err(|_| Error::Config("Background processor is not available".to_string()))?;

        // Wait for the result with a timeout
        let result = timeout(Duration::from_secs(45), result_receiver).await;

        match result {
            Ok(Ok(Ok(bytes))) => {
                info!(job_id = %job_id, size = bytes.len(), "Background snapshot job completed successfully");
                Ok(bytes)
            }
            Ok(Ok(Err(error))) => {
                warn!(job_id = %job_id, error = %error, "Background snapshot job failed");
                Err(error)
            }
            Ok(Err(_)) => {
                error!(job_id = %job_id, "Background snapshot job result channel closed");
                Err(Error::Config(
                    "Background processing was cancelled".to_string(),
                ))
            }
            Err(_) => {
                error!(job_id = %job_id, "Background snapshot job timed out");
                // Update job status to failed
                {
                    let mut jobs = self.jobs.write().unwrap();
                    if let Some(job) = jobs.get_mut(&job_id) {
                        job.status = JobStatus::Failed;
                        job.error_message = Some("Job timed out after 45 seconds".to_string());
                        job.updated_at = now_iso8601();
                    }
                }
                Err(Error::Config(
                    "Background snapshot processing timed out".to_string(),
                ))
            }
        }
    }

    /// Get the status of a job by ID
    pub fn get_job_status(&self, job_id: &str) -> Option<SnapshotJob> {
        let jobs = self.jobs.read().unwrap();
        jobs.get(job_id).cloned()
    }

    /// Get the result of a completed job
    pub fn get_job_result(&self, job_id: &str) -> Result<Option<Bytes>> {
        let jobs = self.jobs.read().unwrap();
        if let Some(job) = jobs.get(job_id) {
            match job.status {
                JobStatus::Completed => Ok(job.result.clone()),
                JobStatus::Failed => Err(Error::Config(
                    job.error_message
                        .clone()
                        .unwrap_or_else(|| "Job failed".to_string()),
                )),
                _ => Ok(None), // Job not completed yet
            }
        } else {
            Err(Error::Config(format!("Job {} not found", job_id)))
        }
    }

    /// Cancel a pending or processing job
    pub fn cancel_job(&self, job_id: &str) -> Result<()> {
        let mut jobs = self.jobs.write().unwrap();
        if let Some(job) = jobs.get_mut(job_id) {
            match job.status {
                JobStatus::Pending | JobStatus::Processing => {
                    job.status = JobStatus::Cancelled;
                    job.updated_at = now_iso8601();
                    info!(job_id = %job_id, "Job cancelled");
                    Ok(())
                }
                _ => Err(Error::Config(
                    "Job cannot be cancelled in its current state".to_string(),
                )),
            }
        } else {
            Err(Error::Config(format!("Job {} not found", job_id)))
        }
    }

    /// Clean up old completed jobs (older than 1 hour)
    pub fn cleanup_old_jobs(&self) {
        let mut jobs = self.jobs.write().unwrap();
        let cutoff_time = chrono::Utc::now() - chrono::Duration::hours(1);

        let initial_count = jobs.len();
        jobs.retain(|_job_id, job| {
            match job.status {
                JobStatus::Completed | JobStatus::Failed | JobStatus::Cancelled => {
                    // Parse the job's updated_at time and check if it's older than cutoff
                    if let Ok(job_time) = chrono::DateTime::parse_from_rfc3339(&job.updated_at) {
                        job_time.with_timezone(&chrono::Utc) > cutoff_time
                    } else {
                        true // Keep jobs with invalid timestamps to be safe
                    }
                }
                _ => true, // Keep pending and processing jobs
            }
        });

        let cleaned_count = initial_count - jobs.len();
        if cleaned_count > 0 {
            info!(
                cleaned = cleaned_count,
                remaining = jobs.len(),
                "Cleaned up old snapshot jobs"
            );
        }
    }

    /// Background processing loop
    async fn process_requests(
        jobs: Arc<RwLock<HashMap<String, SnapshotJob>>>,
        mut request_receiver: mpsc::UnboundedReceiver<ProcessRequest>,
        limiter: SnapshotResourceLimiter,
    ) {
        info!("Background snapshot processor started");

        while let Some(request) = request_receiver.recv().await {
            let job_id = request.job.id.clone();
            debug!(job_id = %job_id, "Processing snapshot request");

            // Update job status to processing
            {
                let mut jobs_guard = jobs.write().unwrap();
                if let Some(job) = jobs_guard.get_mut(&job_id) {
                    job.status = JobStatus::Processing;
                    job.updated_at = now_iso8601();
                }
            }

            // Process in a blocking task to avoid blocking the async executor
            let jobs_clone = jobs.clone();
            let processing_job = request.job.clone();
            let result_sender = request.result_sender;
            let limiter_clone = limiter.clone();

            tokio::task::spawn_blocking(move || {
                let runtime = tokio::runtime::Handle::current();
                let result = runtime.block_on(async {
                    generate_snapshot_with_ffmpeg(
                        &processing_job.input_path,
                        &processing_job.config,
                        Some(&limiter_clone),
                    )
                    .await
                });

                // Update job status based on result
                {
                    let mut jobs_guard = jobs_clone.write().unwrap();
                    if let Some(job) = jobs_guard.get_mut(&job_id) {
                        job.updated_at = now_iso8601();
                        match &result {
                            Ok(bytes) => {
                                job.status = JobStatus::Completed;
                                job.result = Some(bytes.clone());
                                debug!(job_id = %job_id, size = bytes.len(), "Snapshot job completed successfully");
                            }
                            Err(error) => {
                                job.status = JobStatus::Failed;
                                job.error_message = Some(error.to_string());
                                warn!(job_id = %job_id, error = %error, "Snapshot job failed");
                            }
                        }
                    }
                }

                // Send result back to the waiting caller (if they're still waiting)
                let _ = result_sender.send(result);
            });
        }

        warn!("Background snapshot processor stopped");
    }

    /// Get statistics about the processor
    pub fn get_stats(&self) -> ProcessorStats {
        let jobs = self.jobs.read().unwrap();
        let mut stats = ProcessorStats::default();

        for job in jobs.values() {
            match job.status {
                JobStatus::Pending => stats.pending += 1,
                JobStatus::Processing => stats.processing += 1,
                JobStatus::Completed => stats.completed += 1,
                JobStatus::Failed => stats.failed += 1,
                JobStatus::Cancelled => stats.cancelled += 1,
            }
        }

        stats.total = jobs.len();
        stats.limiter_active_operations = self.limiter.active_operations();
        stats.limiter_total_operations = self.limiter.total_operations();
        stats.limiter_available_permits = self.limiter.available_permits();
        stats.limiter_is_saturated = self.limiter.is_saturated();
        stats
    }
}

impl Default for BackgroundSnapshotProcessor {
    fn default() -> Self {
        Self::new()
    }
}

/// Statistics about the background processor
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct ProcessorStats {
    pub total: usize,
    pub pending: usize,
    pub processing: usize,
    pub completed: usize,
    pub failed: usize,
    pub cancelled: usize,
    pub limiter_active_operations: u64,
    pub limiter_total_operations: u64,
    pub limiter_available_permits: usize,
    pub limiter_is_saturated: bool,
}

#[cfg(test)]
mod tests {
    use super::*;
    use test_support::create_test_id;
    use tokio::fs;

    #[tokio::test]
    async fn test_background_processor_creation() {
        let processor = BackgroundSnapshotProcessor::new();
        let stats = processor.get_stats();
        assert_eq!(stats.total, 0);
    }

    #[tokio::test]
    async fn test_submit_job() {
        let processor = BackgroundSnapshotProcessor::new();
        let test_id = create_test_id();
        let temp_dir = std::env::temp_dir().join(format!("gl_capture_test_{}", test_id));
        tokio::fs::create_dir_all(&temp_dir).await.unwrap();
        let test_file = temp_dir.join("test.mp4");

        // Create a dummy file
        fs::write(&test_file, b"fake video data").await.unwrap();

        let config = SnapshotConfig::default();
        let job_id = processor.submit_job(test_file, config).await.unwrap();

        // Job should be created
        let job = processor.get_job_status(&job_id);
        assert!(job.is_some());
        assert_eq!(job.unwrap().status, JobStatus::Pending);
    }

    #[tokio::test]
    async fn test_cancel_job() {
        let processor = BackgroundSnapshotProcessor::new();
        let test_id = create_test_id();
        let temp_dir = std::env::temp_dir().join(format!("gl_capture_test_{}", test_id));
        tokio::fs::create_dir_all(&temp_dir).await.unwrap();
        let test_file = temp_dir.join("test.mp4");

        // Create a dummy file
        fs::write(&test_file, b"fake video data").await.unwrap();

        let config = SnapshotConfig::default();
        let job_id = processor.submit_job(test_file, config).await.unwrap();

        // Cancel the job
        let result = processor.cancel_job(&job_id);
        assert!(result.is_ok());

        // Job should be cancelled
        let job = processor.get_job_status(&job_id);
        assert!(job.is_some());
        assert_eq!(job.unwrap().status, JobStatus::Cancelled);
    }

    #[tokio::test]
    async fn test_job_not_found() {
        let processor = BackgroundSnapshotProcessor::new();
        let fake_id = "non-existent-job-id";

        let job = processor.get_job_status(fake_id);
        assert!(job.is_none());

        let result = processor.get_job_result(fake_id);
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_processor_stats() {
        let processor = BackgroundSnapshotProcessor::new();
        let test_id = create_test_id();
        let temp_dir = std::env::temp_dir().join(format!("gl_capture_test_{}", test_id));
        tokio::fs::create_dir_all(&temp_dir).await.unwrap();
        let test_file = temp_dir.join("test.mp4");

        // Create a dummy file
        fs::write(&test_file, b"fake video data").await.unwrap();

        let config = SnapshotConfig::default();
        let _job_id = processor.submit_job(test_file, config).await.unwrap();

        let stats = processor.get_stats();
        assert_eq!(stats.total, 1);
        assert_eq!(stats.pending, 1);
    }
}
