//! ABOUTME: Analysis pipeline and rule engine for processing frames and events
//! ABOUTME: Composes motion detection, AI analysis, and rule-based notifications

use async_trait::async_trait;
use bytes::Bytes;
use chrono::{DateTime, Datelike, Utc};
use gl_core::{Id, Result};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tracing::{debug, info};

/// Helper trait for string title case conversion
trait ToTitleCase {
    fn to_title_case(&self) -> String;
}

impl ToTitleCase for str {
    fn to_title_case(&self) -> String {
        self.split_whitespace()
            .map(|word| {
                let mut chars = word.chars();
                match chars.next() {
                    None => String::new(),
                    Some(first) => {
                        first.to_uppercase().collect::<String>() + &chars.as_str().to_lowercase()
                    }
                }
            })
            .collect::<Vec<_>>()
            .join(" ")
    }
}

pub mod pipeline;
pub mod processors;
pub mod rule_engine;

pub use pipeline::AnalysisPipeline;
pub use processors::{AiDescriptionProcessor, MotionProcessor, SummaryProcessor};
pub use rule_engine::{Action, Condition, Rule, RuleEngine, RuleSet};

/// Core trait for analysis processors
#[async_trait]
pub trait Processor: Send + Sync {
    /// Process input data and return analysis events
    async fn process(&mut self, input: ProcessorInput) -> Result<Vec<AnalysisEvent>>;

    /// Get processor name for debugging and configuration
    fn name(&self) -> &'static str;

    /// Reset processor state if needed
    async fn reset(&mut self) -> Result<()> {
        Ok(())
    }
}

/// Input data for processors
#[derive(Debug, Clone)]
pub struct ProcessorInput {
    /// Template ID that triggered this analysis
    pub template_id: String,
    /// Raw frame data (if applicable)
    pub frame_data: Option<Bytes>,
    /// Frame format (jpeg, png, etc.)
    pub frame_format: Option<String>,
    /// Text content to analyze (if applicable)
    pub text_content: Option<String>,
    /// Additional context and metadata
    pub context: ProcessorContext,
    /// Timestamp of the input
    pub timestamp: DateTime<Utc>,
}

/// Context information for processors
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessorContext {
    /// Source identifier (camera, sensor, etc.)
    pub source_id: String,
    /// Previous events from this session
    pub previous_events: Vec<AnalysisEvent>,
    /// Template configuration
    pub template_config: HashMap<String, serde_json::Value>,
    /// Custom metadata
    pub metadata: HashMap<String, String>,
}

impl ProcessorContext {
    pub fn new(source_id: String) -> Self {
        Self {
            source_id,
            previous_events: Vec::new(),
            template_config: HashMap::new(),
            metadata: HashMap::new(),
        }
    }

    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }

    pub fn with_config(mut self, config: HashMap<String, serde_json::Value>) -> Self {
        self.template_config = config;
        self
    }
}

/// Analysis event generated by processors
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnalysisEvent {
    /// Unique event identifier
    pub id: String,
    /// Template ID that generated this event
    pub template_id: String,
    /// Event type (motion, person_detected, fire_alert, etc.)
    pub event_type: String,
    /// Event severity level
    pub severity: EventSeverity,
    /// Confidence level (0.0 to 1.0)
    pub confidence: f64,
    /// Human-readable description
    pub description: String,
    /// Structured metadata
    pub metadata: HashMap<String, serde_json::Value>,
    /// Processor that generated this event
    pub processor_name: String,
    /// Source identifier
    pub source_id: String,
    /// Event timestamp
    pub timestamp: DateTime<Utc>,
    /// Whether this event should trigger notifications
    pub should_notify: bool,
    /// Suggested actions for this event
    pub suggested_actions: Vec<String>,
}

/// Event severity levels
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]
pub enum EventSeverity {
    Info,
    Low,
    Medium,
    High,
    Critical,
}

impl EventSeverity {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::Info => "info",
            Self::Low => "low",
            Self::Medium => "medium",
            Self::High => "high",
            Self::Critical => "critical",
        }
    }
}

impl AnalysisEvent {
    /// Create a new analysis event
    pub fn new(
        template_id: String,
        event_type: String,
        severity: EventSeverity,
        confidence: f64,
        description: String,
        processor_name: String,
        source_id: String,
    ) -> Self {
        Self {
            id: Id::new().to_string(),
            template_id,
            event_type,
            severity,
            confidence,
            description,
            metadata: HashMap::new(),
            processor_name,
            source_id,
            timestamp: Utc::now(),
            should_notify: true,
            suggested_actions: Vec::new(),
        }
    }

    /// Add metadata to the event
    pub fn with_metadata(mut self, key: String, value: serde_json::Value) -> Self {
        self.metadata.insert(key, value);
        self
    }

    /// Add suggested actions
    pub fn with_actions(mut self, actions: Vec<String>) -> Self {
        self.suggested_actions = actions;
        self
    }

    /// Set notification flag
    pub fn with_notification(mut self, should_notify: bool) -> Self {
        self.should_notify = should_notify;
        self
    }
}

/// Configuration for analysis processing
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnalysisConfig {
    /// Enabled processors in order
    pub enabled_processors: Vec<String>,
    /// Configuration for each processor
    pub processor_configs: HashMap<String, serde_json::Value>,
    /// Rule engine configuration
    pub rules: Option<RuleSet>,
    /// Event storage configuration
    pub storage: StorageConfig,
    /// Notification configuration
    pub notifications: NotificationConfig,
    /// AI client configuration
    pub ai: Option<gl_ai::AiConfig>,
}

/// Storage configuration for events
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageConfig {
    /// Whether to store events in database
    pub store_events: bool,
    /// Maximum events to keep per template
    pub max_events_per_template: usize,
    /// Event retention period in days
    pub retention_days: u32,
}

/// Notification configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NotificationConfig {
    /// Whether notifications are enabled
    pub enabled: bool,
    /// Minimum severity for notifications
    pub min_severity: EventSeverity,
    /// Deduplication window in minutes
    pub dedup_window_minutes: u32,
    /// Quiet hours configuration
    pub quiet_hours: Option<QuietHours>,
}

/// Quiet hours configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QuietHours {
    /// Start time (24-hour format, e.g. "22:00")
    pub start: String,
    /// End time (24-hour format, e.g. "06:00")
    pub end: String,
    /// Days of week (0=Sunday, 6=Saturday)
    pub days: Vec<u8>,
}

impl Default for AnalysisConfig {
    fn default() -> Self {
        Self {
            enabled_processors: vec![
                "motion".to_string(),
                "ai_description".to_string(),
                "summary".to_string(),
            ],
            processor_configs: HashMap::new(),
            rules: None,
            storage: StorageConfig {
                store_events: true,
                max_events_per_template: 1000,
                retention_days: 30,
            },
            notifications: NotificationConfig {
                enabled: true,
                min_severity: EventSeverity::Medium,
                dedup_window_minutes: 5,
                quiet_hours: None,
            },
            ai: None, // Default to no AI configuration
        }
    }
}

/// Analysis service for orchestrating the pipeline
pub struct AnalysisService {
    pipeline: AnalysisPipeline,
    rule_engine: RuleEngine,
    config: AnalysisConfig,
    db_repo: Option<gl_db::AnalysisEventRepository>,
    notification_manager: Option<gl_notify::NotificationManager>,
}

impl AnalysisService {
    /// Create a new analysis service
    pub fn new(config: AnalysisConfig) -> Result<Self> {
        let rule_engine = RuleEngine::new(config.rules.clone());
        let ai_config = config.ai.clone().unwrap_or_default();
        let pipeline = AnalysisPipeline::with_ai_config(
            config.enabled_processors.clone(),
            config.processor_configs.clone(),
            ai_config,
        )?;

        info!(
            "Created analysis service with {} processors",
            config.enabled_processors.len()
        );

        Ok(Self {
            pipeline,
            rule_engine,
            config,
            db_repo: None,
            notification_manager: None,
        })
    }

    /// Create a new analysis service with database and notification support
    pub fn with_persistence(
        config: AnalysisConfig,
        db: gl_db::Db,
        notification_manager: gl_notify::NotificationManager,
    ) -> Result<Self> {
        let rule_engine = RuleEngine::new(config.rules.clone());
        let ai_config = config.ai.clone().unwrap_or_default();
        let pipeline = AnalysisPipeline::with_ai_config(
            config.enabled_processors.clone(),
            config.processor_configs.clone(),
            ai_config,
        )?;

        let db_repo = gl_db::AnalysisEventRepository::new(db);

        info!(
            "Created analysis service with {} processors, database, and notifications",
            config.enabled_processors.len()
        );

        Ok(Self {
            pipeline,
            rule_engine,
            config,
            db_repo: Some(db_repo),
            notification_manager: Some(notification_manager),
        })
    }

    /// Process input through the analysis pipeline
    pub async fn analyze(&mut self, input: ProcessorInput) -> Result<Vec<AnalysisEvent>> {
        debug!("Starting analysis for template: {}", input.template_id);

        // Run through processor pipeline
        let mut events = self.pipeline.process(input.clone()).await?;

        // Apply rule engine to filter/modify events
        events = self.rule_engine.apply_rules(&input, events).await?;

        // Apply configuration filters
        events = self.apply_config_filters(events);

        // Store events if configured
        if self.config.storage.store_events {
            self.store_events(&events).await?;
        }

        // Enqueue notifications
        if self.config.notifications.enabled {
            self.enqueue_notifications(&events).await?;
        }

        info!("Analysis completed: {} events generated", events.len());
        Ok(events)
    }

    /// Apply configuration-based filters
    fn apply_config_filters(&self, mut events: Vec<AnalysisEvent>) -> Vec<AnalysisEvent> {
        // Filter by minimum severity
        let min_severity = &self.config.notifications.min_severity;
        events.retain(|event| event.severity >= *min_severity);

        // Apply quiet hours
        if let Some(quiet_hours) = &self.config.notifications.quiet_hours {
            let now = Utc::now();
            let is_quiet_time = self.is_quiet_time(&now, quiet_hours);

            if is_quiet_time {
                debug!("Suppressing notifications during quiet hours");
                for event in &mut events {
                    event.should_notify = false;
                }
            }
        }

        events
    }

    /// Check if current time is within quiet hours
    fn is_quiet_time(&self, now: &DateTime<Utc>, quiet_hours: &QuietHours) -> bool {
        let weekday = now.weekday().num_days_from_sunday() as u8;

        if !quiet_hours.days.contains(&weekday) {
            return false;
        }

        let current_time = now.format("%H:%M").to_string();

        // Handle same-day quiet hours
        if quiet_hours.start <= quiet_hours.end {
            current_time >= quiet_hours.start && current_time <= quiet_hours.end
        } else {
            // Handle overnight quiet hours (e.g., 22:00 - 06:00)
            current_time >= quiet_hours.start || current_time <= quiet_hours.end
        }
    }

    /// Store events in the database
    async fn store_events(&self, events: &[AnalysisEvent]) -> Result<()> {
        debug!("Storing {} events to database", events.len());

        if let Some(repo) = &self.db_repo {
            for event in events {
                let create_request = gl_db::CreateAnalysisEvent {
                    template_id: event.template_id.clone(),
                    event_type: event.event_type.clone(),
                    severity: event.severity.as_str().to_string(),
                    confidence: event.confidence,
                    description: event.description.clone(),
                    metadata: Some(event.metadata.clone()),
                    processor_name: event.processor_name.clone(),
                    source_id: event.source_id.clone(),
                    should_notify: event.should_notify,
                    suggested_actions: Some(event.suggested_actions.clone()),
                };

                if let Err(e) = repo.create(create_request).await {
                    tracing::error!(
                        event_id = %event.id,
                        error = %e,
                        "Failed to store analysis event"
                    );
                    return Err(gl_core::Error::Database(format!(
                        "Failed to store event {}: {}",
                        event.id, e
                    )));
                }
            }
            debug!("Successfully stored {} events", events.len());
        } else {
            debug!("No database repository configured, skipping event storage");
        }

        Ok(())
    }

    /// Enqueue notifications for events
    async fn enqueue_notifications(&self, events: &[AnalysisEvent]) -> Result<()> {
        let notify_events: Vec<_> = events.iter().filter(|e| e.should_notify).collect();

        if notify_events.is_empty() {
            return Ok(());
        }

        debug!("Enqueueing {} notifications", notify_events.len());

        if let Some(manager) = &self.notification_manager {
            let notify_count = notify_events.len();
            for event in notify_events {
                // Convert event severity to notification kind
                let kind = match event.severity {
                    EventSeverity::Critical => gl_notify::NotificationKind::Error,
                    EventSeverity::High => gl_notify::NotificationKind::Error,
                    EventSeverity::Medium => gl_notify::NotificationKind::Warning,
                    EventSeverity::Low => gl_notify::NotificationKind::Info,
                    EventSeverity::Info => gl_notify::NotificationKind::Info,
                };

                // Create notification title
                let title = format!(
                    "{} Alert: {}",
                    event.severity.as_str().to_uppercase(),
                    event.event_type.replace("_", " ").to_title_case()
                );

                // Create notification body
                let mut body = format!(
                    "Source: {}\nDescription: {}",
                    event.source_id, event.description
                );

                if !event.suggested_actions.is_empty() {
                    body.push_str("\n\nSuggested Actions:\n");
                    for (i, action) in event.suggested_actions.iter().enumerate() {
                        body.push_str(&format!("{}. {}\n", i + 1, action));
                    }
                }

                // For now, we'll create a notification without channels
                // In a real implementation, channels would be configured per template or user
                let notification = gl_notify::Notification::new(
                    kind,
                    title,
                    body,
                    vec![], // No channels configured yet - this would come from template/user settings
                )
                .with_metadata("event_id".to_string(), event.id.clone())
                .with_metadata("template_id".to_string(), event.template_id.clone())
                .with_metadata("source_id".to_string(), event.source_id.clone());

                // Send notification (will be no-op if no channels configured)
                if let Err(e) = manager.send(&notification).await {
                    tracing::warn!(
                        event_id = %event.id,
                        error = %e,
                        "Failed to send notification for event"
                    );
                    // Continue processing other notifications rather than failing completely
                }
            }
            debug!("Processed {} notifications", notify_count);
        } else {
            debug!("No notification manager configured, skipping notification enqueueing");
        }

        Ok(())
    }

    /// Update configuration
    pub async fn update_config(&mut self, config: AnalysisConfig) -> Result<()> {
        info!("Updating analysis service configuration");

        // Recreate pipeline with new config
        self.pipeline = AnalysisPipeline::new(
            config.enabled_processors.clone(),
            config.processor_configs.clone(),
        )?;

        // Update rule engine
        self.rule_engine = RuleEngine::new(config.rules.clone());

        self.config = config;
        Ok(())
    }

    /// Get current configuration
    pub fn config(&self) -> &AnalysisConfig {
        &self.config
    }

    /// Reset all processor states
    pub async fn reset(&mut self) -> Result<()> {
        info!("Resetting analysis service");
        self.pipeline.reset().await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_analysis_event_creation() {
        let event = AnalysisEvent::new(
            "template_123".to_string(),
            "motion_detected".to_string(),
            EventSeverity::Medium,
            0.85,
            "Motion detected in entrance area".to_string(),
            "motion_processor".to_string(),
            "camera_01".to_string(),
        );

        assert_eq!(event.template_id, "template_123");
        assert_eq!(event.event_type, "motion_detected");
        assert_eq!(event.severity, EventSeverity::Medium);
        assert_eq!(event.confidence, 0.85);
        assert!(event.should_notify);
        assert!(!event.id.is_empty());
    }

    #[test]
    fn test_event_severity_ordering() {
        assert!(EventSeverity::Critical > EventSeverity::High);
        assert!(EventSeverity::High > EventSeverity::Medium);
        assert!(EventSeverity::Medium > EventSeverity::Low);
        assert!(EventSeverity::Low > EventSeverity::Info);
    }

    #[test]
    fn test_processor_context() {
        let context = ProcessorContext::new("camera_01".to_string())
            .with_metadata("location".to_string(), "entrance".to_string());

        assert_eq!(context.source_id, "camera_01");
        assert_eq!(
            context.metadata.get("location"),
            Some(&"entrance".to_string())
        );
    }

    #[test]
    fn test_analysis_config_default() {
        let config = AnalysisConfig::default();

        assert_eq!(config.enabled_processors.len(), 3);
        assert!(config.enabled_processors.contains(&"motion".to_string()));
        assert!(config.storage.store_events);
        assert!(config.notifications.enabled);
        assert_eq!(config.notifications.min_severity, EventSeverity::Medium);
    }
}
